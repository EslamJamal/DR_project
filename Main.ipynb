{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, csv_path, root_dir, status=1):\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        self.data_info = pd.read_csv(csv_path)\n",
    "        #image path\n",
    "        self.img_array = np.asarray(self.data_info.iloc[0:,1])\n",
    "        #labels\n",
    "        self.labels = np.asarray(self.data_info.iloc[0:,2], dtype=np.float32)\n",
    "        #length of data\n",
    "        self.data_len = len(self.data_info.index)\n",
    "        #transformations on the batch\n",
    "            #if status = 1 ===> transforms on train images\n",
    "            #if status = 0 ===> transforms on val images\n",
    "        if status == 1:\n",
    "            self.transformations = transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                                       transforms.RandomRotation((90, 180)),\n",
    "                                                       transforms.ToTensor()])\n",
    "        elif status == 0:\n",
    "            self.transformations = transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                                       transforms.ToTensor()])\n",
    "        else:\n",
    "            raise ValueError('Status should be 1 or 0')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.img_array[idx] + '.jpeg')\n",
    "        image = Image.open(img_path,'r')\n",
    "        img_as_tensor = self.transformations(image)\n",
    "        \n",
    "        return {'image':img_as_tensor,'label':self.labels[idx]}\n",
    "        #return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, num_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print 'Epoch {}/{}'.format(epoch, num_epochs - 1)\n",
    "        print '-'*10\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            num_correct = 0\n",
    "            \n",
    "            if phase == 'train':\n",
    "                dataset = dataloader_train\n",
    "            else:\n",
    "                dataset = dataloader_val\n",
    "                \n",
    "            for idx, batch in enumerate(dataset):\n",
    "                data = batch['image']\n",
    "                data = Variable(data)\n",
    "                labels = batch['label']\n",
    "                labels = labels.long()\n",
    "                labels = Variable(labels)\n",
    "                if use_cuda:\n",
    "                    data = data.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, labels)\n",
    "                    _, preds = torch.max(output.data, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                running_loss += loss.item()*data.size(0)\n",
    "                num_correct += torch.sum(preds == labels.data)\n",
    "                del data, labels, output, preds\n",
    "                torch.cuda.empty_cache()\n",
    "                break\n",
    "            epoch_loss =  running_loss / dataset.__len__()\n",
    "            epoch_acc = num_correct.double() / dataset.__len__() \n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                val_acc.append(epoch_acc)\n",
    "                \n",
    "            print '{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc)\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            break    \n",
    "        print \n",
    "        print '='*70\n",
    "        print\n",
    "        break\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print 'Training complete in {:.0f}mins {:.0f}secs'.format(time_elapsed // 60, time_elapsed % 60)\n",
    "    print 'Best accuracy {:.4f}'.format(best_acc * 100)\n",
    "    \n",
    "    model.load_state_dict(best_model_wts) #load it again to return it at the main function\n",
    "    model.save_state_dict('model_name.pt')\n",
    "    \n",
    "    return model, train_losses, train_acc, val_losses, val_acc   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_cpu(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, num_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print 'Epoch {}/{}'.format(epoch, num_epochs - 1)\n",
    "        print '-'*10\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            num_correct = 0\n",
    "            \n",
    "            if phase == 'train':\n",
    "                dataset = dataloader_train\n",
    "            else:\n",
    "                dataset = dataloader_val\n",
    "                \n",
    "            for idx, batch in enumerate(dataset):\n",
    "                data = batch['image']\n",
    "                data = Variable(data)\n",
    "                labels = batch['label']\n",
    "                labels = labels.long()\n",
    "                labels = Variable(labels)\n",
    "                print'labels', labels\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, labels)\n",
    "                    print'loss {}'.format(loss.item())\n",
    "                    _, preds = torch.max(output.data, 1)\n",
    "                    print'predictions', preds\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                running_loss += loss.item()*data.size(0)\n",
    "                print'data size {}'.format(data.size(0))\n",
    "                print'running loss {}'.format(running_loss)\n",
    "                num_correct += torch.sum(preds == labels.data)\n",
    "                print'number of correct hits {}'.format(num_correct)\n",
    "                #del data, labels, output, preds\n",
    "                #torch.cuda.empty_cache()\n",
    "                #break\n",
    "            epoch_loss =  running_loss / dataset.__len__()\n",
    "            epoch_acc = num_correct.double() / dataset.__len__()    \n",
    "           \n",
    "            print '{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc)\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            #break    \n",
    "        print \n",
    "        print '='*70\n",
    "        print\n",
    "        break\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print 'Training complete in {:.0f}mins {:.0f}secs'.format(time_elapsed // 60, time_elapsed % 60)\n",
    "    print 'Best accuracy {:.4f}'.format(best_acc)\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#csv_path = '/media/eslam/7AE0CA83E0CA455B/Users/Eslam100/Documents/kaggledataset/10k_part/train/labels.csv'\n",
    "root_dir = '/media/eslam/7AE0CA83E0CA455B/Users/Eslam100/Documents/kaggledataset/10k_part/'\n",
    "trainset = myDataset(os.path.join(root_dir,'train/labels.csv'), os.path.join(root_dir,'train'))\n",
    "dataloader_train  = DataLoader(dataset=trainset,\n",
    "                         batch_size=10,\n",
    "                         shuffle=True,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True)\n",
    "val_set = myDataset(os.path.join(root_dir,'val/labels.csv'), os.path.join(root_dir,'val'))\n",
    "dataloader_val = DataLoader(dataset=val_set,\n",
    "                         batch_size=10,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True)\n",
    "testset =  myDataset(os.path.join(root_dir,'test/labels.csv'), os.path.join(root_dir,'test'), status=0)\n",
    "dataloader_test = DataLoader(dataset=testset,\n",
    "                         batch_size=15,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3)\n",
    "        self.norm1 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(128, 256, 3)\n",
    "        self.norm2 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, 3)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*12*12,4096)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(4096, 5)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.pool1(self.conv2(F.relu(self.conv1(input))))\n",
    "        x = self.pool2(self.conv4(F.relu(self.conv3(x))))\n",
    "        x = self.pool3(self.conv6(F.relu(self.norm1(self.conv5(x)))))\n",
    "        x = self.pool4(self.conv8(F.relu(self.norm2(self.conv7(x)))))\n",
    "        #flatten the tensor for the FC\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        #return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    \n",
    "def plot_conf_matrix(y_test, y_pred, class_names):\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    print('CCR = {}'.format(np.trace(cnf_matrix) / len(y_test)))\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, dataloader_test, criterion, optimizer, scheduler, num_epochs= 25):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    test_losses = []\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0\n",
    "    total = dataloader_test.__len__()\n",
    "    for idx, batch in enumerate(dataloader_test):\n",
    "        data = batch['image']\n",
    "        data = Variable(data)\n",
    "        labels = batch['label']\n",
    "        labels = labels.long()\n",
    "        labels = Variable(labels)\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            labels = labels.cuda()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        _,preds = torch.max(output.data, 1)\n",
    "        running_loss += loss.data[0]*data.size(0)\n",
    "        num_correct += torch.sum(preds == labels.data)\n",
    "        true.extend(labels.data.cpu().numpy().tolist())\n",
    "        pred.extend(preds.cpu().numpy().tolist())\n",
    "        \n",
    "    accuracy = num_correct/total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Main CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "labels tensor([ 0,  0,  0,  3,  0,  0,  0,  0,  0,  0])\n",
      "loss 1.54013991356\n",
      "predictions tensor([ 0,  0,  4,  0,  1,  0,  0,  0,  3,  0])\n",
      "data size 10\n",
      "running loss 15.4013991356\n",
      "number of correct hits 6\n",
      "labels tensor([ 2,  2,  0,  0,  0,  1,  3,  0,  0,  1])\n",
      "loss 2.76373910904\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 43.038790226\n",
      "number of correct hits 11\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  0,  0,  2,  0])\n",
      "loss 1.31264185905\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 56.1652088165\n",
      "number of correct hits 19\n",
      "labels tensor([ 1,  0,  2,  0,  0,  2,  0,  0,  2,  0])\n",
      "loss 1.24166834354\n",
      "predictions tensor([ 0,  0,  0,  0,  3,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 68.581892252\n",
      "number of correct hits 24\n",
      "labels tensor([ 0,  0,  0,  0,  1,  0,  0,  1,  2,  0])\n",
      "loss 1.40445446968\n",
      "predictions tensor([ 2,  0,  2,  2,  2,  2,  0,  2,  0,  2])\n",
      "data size 10\n",
      "running loss 82.6264369488\n",
      "number of correct hits 26\n",
      "labels tensor([ 0,  1,  0,  1,  1,  0,  0,  3,  0,  2])\n",
      "loss 1.68553519249\n",
      "predictions tensor([ 2,  0,  2,  2,  2,  2,  0,  0,  2,  0])\n",
      "data size 10\n",
      "running loss 99.4817888737\n",
      "number of correct hits 27\n",
      "labels tensor([ 0,  1,  2,  0,  2,  2,  0,  0,  0,  3])\n",
      "loss 1.33341145515\n",
      "predictions tensor([ 0,  0,  0,  0,  2,  0,  0,  1,  0,  0])\n",
      "data size 10\n",
      "running loss 112.815903425\n",
      "number of correct hits 32\n",
      "labels tensor([ 0,  0,  0,  1,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.882681071758\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 121.642714143\n",
      "number of correct hits 41\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  2,  2,  0,  0])\n",
      "loss 0.764393210411\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 129.286646247\n",
      "number of correct hits 49\n",
      "labels tensor([ 1,  0,  0,  0,  0,  0,  0,  0,  0,  2])\n",
      "loss 0.623714327812\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 135.523789525\n",
      "number of correct hits 57\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  3,  0,  0,  0])\n",
      "loss 0.549044787884\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 141.014237404\n",
      "number of correct hits 66\n",
      "labels tensor([ 1,  0,  0,  0,  0,  0,  1,  2,  1,  0])\n",
      "loss 1.72494959831\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 158.263733387\n",
      "number of correct hits 72\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.1221960783\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 159.48569417\n",
      "number of correct hits 82\n",
      "labels tensor([ 0,  0,  0,  0,  2,  1,  0,  0,  0,  0])\n",
      "loss 1.06216645241\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 170.107358694\n",
      "number of correct hits 90\n",
      "labels tensor([ 2,  0,  0,  2,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.772288262844\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 177.830241323\n",
      "number of correct hits 98\n",
      "labels tensor([ 0,  0,  0,  0,  2,  0,  0,  2,  0,  0])\n",
      "loss 0.811925888062\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 185.949500203\n",
      "number of correct hits 106\n",
      "labels tensor([ 0,  0,  0,  0,  2,  2,  2,  0,  0,  0])\n",
      "loss 0.870969414711\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 194.65919435\n",
      "number of correct hits 113\n",
      "labels tensor([ 0,  0,  2,  0,  4,  0,  0,  0,  0,  2])\n",
      "loss 1.46543800831\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 209.313574433\n",
      "number of correct hits 120\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  2,  0,  0,  0])\n",
      "loss 0.555414378643\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  2,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 214.86771822\n",
      "number of correct hits 127\n",
      "labels tensor([ 0,  2,  0,  1,  0,  1,  0,  0,  0,  0])\n",
      "loss 1.1999604702\n",
      "predictions tensor([ 0,  0,  2,  0,  0,  0,  0,  0,  2,  0])\n",
      "data size 10\n",
      "running loss 226.867322922\n",
      "number of correct hits 132\n",
      "labels tensor([ 0,  0,  0,  0,  1,  0,  0,  0,  0,  2])\n",
      "loss 1.2338912487\n",
      "predictions tensor([ 0,  0,  0,  2,  0,  0,  2,  2,  2,  0])\n",
      "data size 10\n",
      "running loss 239.206235409\n",
      "number of correct hits 136\n",
      "labels tensor([ 2,  0,  2,  0,  2,  0,  2,  0,  0,  0])\n",
      "loss 0.848811924458\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  2,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 247.694354653\n",
      "number of correct hits 143\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  4,  2])\n",
      "loss 0.988175690174\n",
      "predictions tensor([ 0,  2,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 257.576111555\n",
      "number of correct hits 150\n",
      "labels tensor([ 0,  1,  0,  0,  0,  0,  0,  0,  0,  2])\n",
      "loss 0.961505115032\n",
      "predictions tensor([ 0,  2,  0,  0,  0,  0,  0,  2,  0,  0])\n",
      "data size 10\n",
      "running loss 267.191162705\n",
      "number of correct hits 157\n",
      "labels tensor([ 0,  4,  2,  0,  3,  0,  0,  0,  0,  0])\n",
      "loss 1.93395936489\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  2,  0,  0,  2])\n",
      "data size 10\n",
      "running loss 286.530756354\n",
      "number of correct hits 162\n",
      "labels tensor([ 0,  1,  1,  0,  0,  2,  0,  0,  4,  0])\n",
      "loss 1.64625859261\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 302.99334228\n",
      "number of correct hits 168\n",
      "labels tensor([ 0,  0,  4,  0,  2,  0,  4,  0,  0,  0])\n",
      "loss 1.06400537491\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 313.633396029\n",
      "number of correct hits 175\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  0,  0,  2,  0])\n",
      "loss 0.693296670914\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 320.566362739\n",
      "number of correct hits 183\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  2,  1,  0,  0])\n",
      "loss 0.853561580181\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 329.10197854\n",
      "number of correct hits 190\n",
      "labels tensor([ 0,  3,  2,  2,  0,  0,  2,  0,  0,  0])\n",
      "loss 1.24135017395\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 341.51548028\n",
      "number of correct hits 196\n",
      "labels tensor([ 0,  0,  0,  3,  0,  0,  2,  0,  0,  0])\n",
      "loss 0.891247749329\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 350.427957773\n",
      "number of correct hits 204\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.421575933695\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 354.64371711\n",
      "number of correct hits 214\n",
      "labels tensor([ 2,  0,  0,  2,  0,  0,  0,  0,  1,  0])\n",
      "loss 1.34008789062\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 368.044596016\n",
      "number of correct hits 221\n",
      "labels tensor([ 0,  1,  0,  2,  0,  0,  0,  4,  4,  0])\n",
      "loss 1.4698574543\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 382.743170559\n",
      "number of correct hits 227\n",
      "labels tensor([ 0,  0,  0,  0,  1,  0,  0,  2,  0,  0])\n",
      "loss 0.700152158737\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 389.744692147\n",
      "number of correct hits 235\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  2,  0,  1,  0])\n",
      "loss 0.844074606895\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 398.185438216\n",
      "number of correct hits 242\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  2,  0,  0,  0])\n",
      "loss 0.533592522144\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 403.521363437\n",
      "number of correct hits 250\n",
      "labels tensor([ 1,  0,  0,  0,  0,  0,  2,  0,  2,  0])\n",
      "loss 0.853196263313\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 412.05332607\n",
      "number of correct hits 257\n",
      "labels tensor([ 2,  0,  0,  0,  0,  1,  1,  0,  0,  0])\n",
      "loss 1.03249228001\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 422.37824887\n",
      "number of correct hits 264\n",
      "labels tensor([ 0,  1,  0,  0,  0,  0,  2,  0,  0,  2])\n",
      "loss 0.924966037273\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 431.627909243\n",
      "number of correct hits 271\n",
      "labels tensor([ 2,  3,  2,  2,  1,  0,  0,  0,  2,  0])\n",
      "loss 1.51627850533\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 10\n",
      "running loss 446.790694296\n",
      "number of correct hits 275\n",
      "labels tensor([ 0,  0,  0,  1,  0,  0,  0,  0,  2,  0])\n",
      "loss 1.43693804741\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 461.16007477\n",
      "number of correct hits 283\n",
      "labels tensor([ 0,  0,  1,  1,  2,  2,  0,  0,  0,  0])\n",
      "loss 1.01371884346\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 471.297263205\n",
      "number of correct hits 289\n",
      "labels tensor([ 2,  0,  1,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.858507990837\n",
      "predictions tensor([ 2,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 479.882343113\n",
      "number of correct hits 298\n",
      "labels tensor([ 1,  2,  1,  0,  0,  3,  0,  1,  0,  0])\n",
      "loss 1.37051463127\n",
      "predictions tensor([ 0,  0,  2,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 493.587489426\n",
      "number of correct hits 303\n",
      "labels tensor([ 0,  1,  0,  3,  3,  2,  0,  1,  0,  0])\n",
      "loss 1.78411543369\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 511.428643763\n",
      "number of correct hits 308\n",
      "labels tensor([ 1,  0,  0,  0,  0,  0,  0,  4,  0,  1])\n",
      "loss 0.998818695545\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 521.416830719\n",
      "number of correct hits 315\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  1,  3,  2])\n",
      "loss 1.26616466045\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 534.078477323\n",
      "number of correct hits 322\n",
      "labels tensor([ 0,  1,  0,  0,  0,  3,  1,  0,  0,  0])\n",
      "loss 1.20815420151\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 546.160019338\n",
      "number of correct hits 329\n",
      "labels tensor([ 0,  0,  0,  0,  4,  0,  0,  0,  0,  1])\n",
      "loss 0.983351409435\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 555.993533432\n",
      "number of correct hits 337\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  2,  0,  1,  0])\n",
      "loss 0.970167160034\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 565.695205033\n",
      "number of correct hits 344\n",
      "labels tensor([ 0,  4,  0,  0,  0,  0,  0,  2,  1,  1])\n",
      "loss 1.47249102592\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 580.420115292\n",
      "number of correct hits 350\n",
      "labels tensor([ 0,  0,  2,  4,  1,  0,  2,  1,  2,  0])\n",
      "loss 1.65439891815\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 596.964104474\n",
      "number of correct hits 354\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  0,  1,  1,  0])\n",
      "loss 0.988867461681\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 606.85277909\n",
      "number of correct hits 361\n",
      "labels tensor([ 0,  2,  0,  2,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.752728998661\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 614.380069077\n",
      "number of correct hits 369\n",
      "labels tensor([ 0,  0,  0,  0,  1,  1,  0,  0,  2,  0])\n",
      "loss 0.894879937172\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 623.328868449\n",
      "number of correct hits 376\n",
      "labels tensor([ 0,  0,  2,  2,  0,  2,  4,  0,  0,  0])\n",
      "loss 1.50340211391\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 638.362889588\n",
      "number of correct hits 382\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2])\n",
      "loss 0.575737595558\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 644.120265543\n",
      "number of correct hits 391\n",
      "labels tensor([ 4,  0,  0,  0,  0,  3,  0,  2,  1,  1])\n",
      "loss 2.2332816124\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 666.453081667\n",
      "number of correct hits 396\n",
      "labels tensor([ 0,  1,  1,  0,  0,  1,  0,  0,  0,  2])\n",
      "loss 1.24187159538\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 678.871797621\n",
      "number of correct hits 402\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.576246857643\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 684.634266198\n",
      "number of correct hits 411\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  0,  0,  1,  2])\n",
      "loss 0.829249560833\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 692.926761806\n",
      "number of correct hits 418\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  0,  0,  0,  1])\n",
      "loss 0.697667717934\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 699.903438985\n",
      "number of correct hits 426\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  2,  2,  0,  0])\n",
      "loss 1.08495187759\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 710.752957761\n",
      "number of correct hits 433\n",
      "labels tensor([ 0,  0,  0,  0,  2,  0,  0,  0,  2,  0])\n",
      "loss 0.595387041569\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 716.706828177\n",
      "number of correct hits 441\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  0,  2,  2,  0])\n",
      "loss 0.751430630684\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 724.221134484\n",
      "number of correct hits 448\n",
      "labels tensor([ 0,  0,  1,  0,  0,  0,  0,  2,  1,  0])\n",
      "loss 1.04877793789\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 734.708913863\n",
      "number of correct hits 455\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  1,  0,  0,  2])\n",
      "loss 0.667927920818\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 741.388193071\n",
      "number of correct hits 463\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  0,  2,  0,  0])\n",
      "loss 0.393347293139\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 745.321666002\n",
      "number of correct hits 471\n",
      "labels tensor([ 0,  1,  0,  0,  0,  0,  1,  2,  0,  0])\n",
      "loss 0.982836127281\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 755.150027275\n",
      "number of correct hits 478\n",
      "labels tensor([ 0,  0,  2,  0,  0,  3,  0,  2,  2,  2])\n",
      "loss 1.44414043427\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 769.591431618\n",
      "number of correct hits 483\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2])\n",
      "loss 0.823809504509\n",
      "predictions tensor([ 0,  0,  0,  2,  2,  0,  0,  0,  0,  2])\n",
      "data size 10\n",
      "running loss 777.829526663\n",
      "number of correct hits 491\n",
      "labels tensor([ 0,  0,  0,  2,  1,  0,  0,  3,  2,  2])\n",
      "loss 1.93519341946\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  2,  0,  2,  0,  2])\n",
      "data size 10\n",
      "running loss 797.181460857\n",
      "number of correct hits 496\n",
      "labels tensor([ 2,  0,  1,  1,  1,  0,  0,  0,  0,  0])\n",
      "loss 1.56689715385\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 812.850432396\n",
      "number of correct hits 502\n",
      "labels tensor([ 2,  0,  0,  0,  3,  0,  0,  2,  2,  0])\n",
      "loss 1.17068421841\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 824.55727458\n",
      "number of correct hits 508\n",
      "labels tensor([ 2,  0,  0,  2,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.857317566872\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 833.130450249\n",
      "number of correct hits 515\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  4,  0,  0,  0])\n",
      "loss 1.1949365139\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 845.079815388\n",
      "number of correct hits 523\n",
      "labels tensor([ 0,  0,  2,  0,  2,  0,  0,  0,  0,  2])\n",
      "loss 0.818904697895\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 853.268862367\n",
      "number of correct hits 530\n",
      "labels tensor([ 0,  2,  2,  0,  0,  0,  3,  0,  1,  0])\n",
      "loss 1.39946043491\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  2,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 867.263466716\n",
      "number of correct hits 536\n",
      "labels tensor([ 0,  0,  0,  0,  2,  3,  0,  0,  1,  0])\n",
      "loss 0.992070198059\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 877.184168696\n",
      "number of correct hits 543\n",
      "labels tensor([ 0,  0,  0,  1,  0,  0,  0,  3,  2,  2])\n",
      "loss 1.21366357803\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 889.320804477\n",
      "number of correct hits 549\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.401836693287\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 893.33917141\n",
      "number of correct hits 559\n",
      "labels tensor([ 2,  0,  1,  0,  0,  0,  0,  0,  0,  1])\n",
      "loss 1.00962734222\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 903.435444832\n",
      "number of correct hits 566\n",
      "labels tensor([ 0,  0,  0,  0,  0,  3,  0,  0,  0,  4])\n",
      "loss 0.985188305378\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 913.287327886\n",
      "number of correct hits 574\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  2])\n",
      "loss 0.828005969524\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 921.567387581\n",
      "number of correct hits 582\n",
      "labels tensor([ 2,  0,  0,  0,  0,  1,  2,  0,  0,  0])\n",
      "loss 1.08166909218\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 932.384078503\n",
      "number of correct hits 589\n",
      "labels tensor([ 2,  3,  0,  2,  0,  2,  0,  0,  0,  3])\n",
      "loss 1.93118703365\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 951.695948839\n",
      "number of correct hits 594\n",
      "labels tensor([ 0,  1,  4,  2,  2,  0,  2,  3,  0,  0])\n",
      "loss 2.15150213242\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 973.210970163\n",
      "number of correct hits 598\n",
      "labels tensor([ 2,  0,  2,  0,  0,  0,  0,  0,  0,  1])\n",
      "loss 1.19121754169\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 985.12314558\n",
      "number of correct hits 605\n",
      "labels tensor([ 2,  0,  0,  2,  1,  0,  2,  0,  0,  0])\n",
      "loss 1.03337466717\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 995.456892252\n",
      "number of correct hits 611\n",
      "labels tensor([ 0,  0,  0,  0,  0,  1,  0,  0,  2,  0])\n",
      "loss 0.879320800304\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1004.25010026\n",
      "number of correct hits 619\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  0,  0,  0,  2])\n",
      "loss 0.855350971222\n",
      "predictions tensor([ 2,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1012.80360997\n",
      "number of correct hits 626\n",
      "labels tensor([ 1,  0,  0,  2,  3,  2,  0,  2,  0,  0])\n",
      "loss 1.16986298561\n",
      "predictions tensor([ 2,  0,  0,  0,  0,  1,  2,  0,  2,  0])\n",
      "data size 10\n",
      "running loss 1024.50223982\n",
      "number of correct hits 629\n",
      "labels tensor([ 0,  0,  0,  0,  0,  4,  0,  1,  2,  0])\n",
      "loss 1.38945937157\n",
      "predictions tensor([ 0,  0,  2,  0,  0,  0,  1,  0,  2,  0])\n",
      "data size 10\n",
      "running loss 1038.39683354\n",
      "number of correct hits 635\n",
      "labels tensor([ 0,  0,  2,  0,  2,  2,  0,  2,  1,  0])\n",
      "loss 1.13092470169\n",
      "predictions tensor([ 0,  0,  0,  2,  0,  0,  0,  2,  2,  2])\n",
      "data size 10\n",
      "running loss 1049.70608056\n",
      "number of correct hits 639\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.721215069294\n",
      "predictions tensor([ 0,  0,  2,  0,  0,  0,  0,  0,  0,  2])\n",
      "data size 10\n",
      "running loss 1056.91823125\n",
      "number of correct hits 647\n",
      "labels tensor([ 0,  0,  0,  0,  0,  1,  0,  2,  3,  0])\n",
      "loss 1.35593986511\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  2,  0,  2,  0])\n",
      "data size 10\n",
      "running loss 1070.4776299\n",
      "number of correct hits 653\n",
      "labels tensor([ 0,  0,  2,  0,  0,  3,  0,  4,  2,  2])\n",
      "loss 1.53398489952\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1085.8174789\n",
      "number of correct hits 658\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.494545757771\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1090.76293647\n",
      "number of correct hits 667\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  2,  2,  0,  0])\n",
      "loss 0.837667942047\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1099.13961589\n",
      "number of correct hits 674\n",
      "labels tensor([ 0,  0,  2,  3,  0,  4,  2,  2,  0,  2])\n",
      "loss 1.81397974491\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1117.27941334\n",
      "number of correct hits 678\n",
      "labels tensor([ 1,  0,  0,  2,  0,  1,  0,  0,  2,  0])\n",
      "loss 1.24725329876\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1129.75194633\n",
      "number of correct hits 684\n",
      "labels tensor([ 0,  0,  0,  1,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.781215429306\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  2,  2,  0,  0])\n",
      "data size 10\n",
      "running loss 1137.56410062\n",
      "number of correct hits 691\n",
      "labels tensor([ 0,  0,  0,  2,  4,  0,  1,  0,  0,  0])\n",
      "loss 1.12643647194\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0])\n",
      "data size 10\n",
      "running loss 1148.82846534\n",
      "number of correct hits 697\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  2,  0,  0,  2])\n",
      "loss 0.709433674812\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1155.92280209\n",
      "number of correct hits 705\n",
      "labels tensor([ 0,  2,  0,  3,  0,  0,  0,  0,  0,  3])\n",
      "loss 1.03347361088\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1166.2575382\n",
      "number of correct hits 712\n",
      "labels tensor([ 0,  0,  0,  1,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.988700211048\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1176.14454031\n",
      "number of correct hits 720\n",
      "labels tensor([ 0,  0,  0,  0,  2,  0,  2,  0,  1,  2])\n",
      "loss 1.22575819492\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1188.40212226\n",
      "number of correct hits 726\n",
      "labels tensor([ 2,  0,  1,  0,  0,  0,  0,  0,  1,  0])\n",
      "loss 1.01746058464\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1198.57672811\n",
      "number of correct hits 733\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  4,  0,  4,  0])\n",
      "loss 1.11474049091\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1209.72413301\n",
      "number of correct hits 741\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0])\n",
      "loss 0.563667714596\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1215.36081016\n",
      "number of correct hits 750\n",
      "labels tensor([ 0,  0,  2,  0,  0,  2,  0,  0,  2,  0])\n",
      "loss 1.09344518185\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1226.29526198\n",
      "number of correct hits 757\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0])\n",
      "loss 0.4789942801\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1231.08520478\n",
      "number of correct hits 766\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  0,  0,  2,  2])\n",
      "loss 0.748662590981\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1238.57183069\n",
      "number of correct hits 773\n",
      "labels tensor([ 2,  0,  0,  0,  2,  0,  0,  0,  0,  0])\n",
      "loss 0.786082327366\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1246.43265396\n",
      "number of correct hits 781\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  2,  0,  4,  4])\n",
      "loss 1.1416823864\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1257.84947783\n",
      "number of correct hits 788\n",
      "labels tensor([ 0,  0,  0,  0,  2,  3,  0,  0,  2,  2])\n",
      "loss 1.169683218\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1269.54631001\n",
      "number of correct hits 794\n",
      "labels tensor([ 1,  0,  0,  0,  0,  2,  3,  1,  3,  0])\n",
      "loss 2.20037412643\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1291.55005127\n",
      "number of correct hits 799\n",
      "labels tensor([ 2,  2,  0,  2,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.71035182476\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1298.65356952\n",
      "number of correct hits 806\n",
      "labels tensor([ 0,  0,  2,  0,  1,  0,  1,  0,  0,  0])\n",
      "loss 1.08914017677\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1309.54497129\n",
      "number of correct hits 813\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.607843756676\n",
      "predictions tensor([ 2,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1315.62340885\n",
      "number of correct hits 822\n",
      "labels tensor([ 0,  0,  0,  1,  0,  2,  0,  0,  0,  2])\n",
      "loss 0.858467102051\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 10\n",
      "running loss 1324.20807987\n",
      "number of correct hits 829\n",
      "labels tensor([ 0,  0,  0,  0,  4,  0,  2,  0,  0,  0])\n",
      "loss 0.884171307087\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1333.04979295\n",
      "number of correct hits 837\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.538504302502\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1338.43483597\n",
      "number of correct hits 847\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0])\n",
      "loss 0.554490864277\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1343.97974461\n",
      "number of correct hits 856\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.392922222614\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1347.90896684\n",
      "number of correct hits 865\n",
      "labels tensor([ 1,  0,  0,  0,  0,  4,  0,  0,  2,  0])\n",
      "loss 1.10533642769\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1358.96233112\n",
      "number of correct hits 872\n",
      "labels tensor([ 0,  1,  0,  0,  0,  0,  4,  0,  0,  0])\n",
      "loss 1.03353965282\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1369.29772764\n",
      "number of correct hits 880\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  1,  0,  0,  0])\n",
      "loss 0.786268889904\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1377.16041654\n",
      "number of correct hits 888\n",
      "labels tensor([ 1,  0,  0,  0,  1,  0,  0,  1,  0,  1])\n",
      "loss 1.28203177452\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1389.98073429\n",
      "number of correct hits 894\n",
      "labels tensor([ 1,  0,  0,  0,  0,  0,  0,  0,  3,  0])\n",
      "loss 1.19691359997\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1401.94987029\n",
      "number of correct hits 902\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  3,  0,  0])\n",
      "loss 0.605354011059\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1408.0034104\n",
      "number of correct hits 911\n",
      "labels tensor([ 0,  2,  1,  0,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.925122559071\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1417.25463599\n",
      "number of correct hits 918\n",
      "labels tensor([ 2,  0,  0,  0,  0,  2,  0,  4,  0,  0])\n",
      "loss 1.13409912586\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1428.59562725\n",
      "number of correct hits 925\n",
      "labels tensor([ 0,  2,  0,  0,  2,  1,  0,  0,  0,  0])\n",
      "loss 0.871742248535\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1437.31304973\n",
      "number of correct hits 932\n",
      "labels tensor([ 0,  0,  2,  4,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.824659943581\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1445.55964917\n",
      "number of correct hits 940\n",
      "labels tensor([ 0,  0,  0,  0,  2,  0,  3,  0,  0,  0])\n",
      "loss 1.00471377373\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1455.60678691\n",
      "number of correct hits 948\n",
      "labels tensor([ 1,  2,  2,  0,  0,  0,  1,  2,  2,  2])\n",
      "loss 1.77889192104\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1473.39570612\n",
      "number of correct hits 951\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.703220486641\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  2,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1480.42791098\n",
      "number of correct hits 959\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.668467581272\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  2,  0])\n",
      "data size 10\n",
      "running loss 1487.1125868\n",
      "number of correct hits 966\n",
      "labels tensor([ 0,  2,  1,  0,  2,  0,  0,  1,  0,  2])\n",
      "loss 1.51040482521\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0])\n",
      "data size 10\n",
      "running loss 1502.21663505\n",
      "number of correct hits 971\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.493686765432\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2])\n",
      "data size 10\n",
      "running loss 1507.1535027\n",
      "number of correct hits 980\n",
      "labels tensor([ 0,  0,  0,  1,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.787478327751\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1515.02828598\n",
      "number of correct hits 989\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.270931273699\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1517.73759872\n",
      "number of correct hits 999\n",
      "labels tensor([ 2,  2,  0,  1,  0,  0,  0,  2,  0,  0])\n",
      "loss 1.03419268131\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1528.07952553\n",
      "number of correct hits 1005\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  2,  2])\n",
      "loss 0.525668144226\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1533.33620697\n",
      "number of correct hits 1013\n",
      "labels tensor([ 0,  0,  1,  0,  2,  1,  0,  0,  2,  0])\n",
      "loss 1.71906888485\n",
      "predictions tensor([ 0,  0,  2,  0,  0,  0,  0,  2,  0,  2])\n",
      "data size 10\n",
      "running loss 1550.52689582\n",
      "number of correct hits 1017\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  0,  0,  0,  3])\n",
      "loss 1.04451084137\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1560.97200423\n",
      "number of correct hits 1025\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.462882041931\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1565.60082465\n",
      "number of correct hits 1034\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  0,  2])\n",
      "loss 0.83080881834\n",
      "predictions tensor([ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1573.90891284\n",
      "number of correct hits 1041\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  0,  2,  2,  3])\n",
      "loss 1.70475041866\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1590.95641702\n",
      "number of correct hits 1047\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2])\n",
      "loss 0.404914557934\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1595.0055626\n",
      "number of correct hits 1056\n",
      "labels tensor([ 0,  0,  2,  0,  0,  2,  0,  0,  0,  0])\n",
      "loss 0.522046327591\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1600.22602588\n",
      "number of correct hits 1064\n",
      "labels tensor([ 2,  2,  0,  0,  2,  2,  0,  1,  2,  0])\n",
      "loss 1.42409348488\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1614.46696073\n",
      "number of correct hits 1068\n",
      "labels tensor([ 0,  0,  0,  0,  0,  3,  0,  4,  0,  0])\n",
      "loss 1.32751059532\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1627.74206668\n",
      "number of correct hits 1076\n",
      "labels tensor([ 3,  1,  0,  0,  0,  0,  0,  2,  2,  2])\n",
      "loss 1.66816973686\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1644.42376405\n",
      "number of correct hits 1081\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0])\n",
      "loss 0.687638878822\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1651.30015284\n",
      "number of correct hits 1090\n",
      "labels tensor([ 0,  2,  0,  4,  0,  0,  0,  0,  2,  0])\n",
      "loss 1.1309915781\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1662.61006862\n",
      "number of correct hits 1097\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.704378843307\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1669.65385705\n",
      "number of correct hits 1105\n",
      "labels tensor([ 0,  0,  0,  2,  0,  2,  1,  2,  0,  0])\n",
      "loss 0.983458518982\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1679.48844224\n",
      "number of correct hits 1111\n",
      "labels tensor([ 2,  2,  1,  0,  1,  0,  0,  0,  0,  0])\n",
      "loss 1.04888987541\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1689.977341\n",
      "number of correct hits 1117\n",
      "labels tensor([ 4,  0,  0,  2,  0,  0,  2,  4,  1,  2])\n",
      "loss 1.9899597168\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1709.87693816\n",
      "number of correct hits 1121\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  0,  0,  0,  1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.693443775177\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1716.81137592\n",
      "number of correct hits 1129\n",
      "labels tensor([ 2,  2,  0,  0,  0,  0,  4,  2,  0,  2])\n",
      "loss 1.38601565361\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1730.67153245\n",
      "number of correct hits 1134\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0])\n",
      "loss 0.709245383739\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1737.76398629\n",
      "number of correct hits 1143\n",
      "labels tensor([ 0,  0,  0,  1,  1,  0,  0,  0,  0,  0])\n",
      "loss 0.897833347321\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1746.74231976\n",
      "number of correct hits 1151\n",
      "labels tensor([ 0,  0,  0,  1,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.676973223686\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1753.512052\n",
      "number of correct hits 1160\n",
      "labels tensor([ 0,  1,  0,  0,  2,  3,  0,  0,  3,  0])\n",
      "loss 1.55423760414\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1769.05442804\n",
      "number of correct hits 1166\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  0,  0,  0,  1])\n",
      "loss 0.694899737835\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1776.00342542\n",
      "number of correct hits 1174\n",
      "labels tensor([ 2,  0,  0,  2,  0,  0,  2,  0,  0,  0])\n",
      "loss 1.11210882664\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1787.12451369\n",
      "number of correct hits 1181\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.22971406579\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1789.42165434\n",
      "number of correct hits 1191\n",
      "labels tensor([ 0,  0,  0,  0,  1,  2,  0,  0,  1,  0])\n",
      "loss 1.07973253727\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1800.21897972\n",
      "number of correct hits 1198\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  0,  0,  1,  2])\n",
      "loss 0.970430552959\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1809.92328525\n",
      "number of correct hits 1205\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.24565911293\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1812.37987638\n",
      "number of correct hits 1215\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.372337639332\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1816.10325277\n",
      "number of correct hits 1224\n",
      "labels tensor([ 0,  0,  4,  0,  0,  0,  0,  0,  0,  2])\n",
      "loss 0.754066765308\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1823.64392042\n",
      "number of correct hits 1232\n",
      "labels tensor([ 0,  2,  2,  0,  2,  1,  0,  0,  0,  0])\n",
      "loss 1.56860339642\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1839.32995439\n",
      "number of correct hits 1238\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.143159896135\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1840.76155335\n",
      "number of correct hits 1248\n",
      "labels tensor([ 0,  2,  0,  2,  0,  0,  1,  0,  0,  0])\n",
      "loss 0.739093124866\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1848.1524846\n",
      "number of correct hits 1255\n",
      "labels tensor([ 3,  0,  0,  0,  0,  0,  2,  0,  0,  0])\n",
      "loss 0.997515678406\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1858.12764138\n",
      "number of correct hits 1263\n",
      "labels tensor([ 0,  2,  0,  3,  0,  0,  0,  0,  0,  0])\n",
      "loss 1.13436055183\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1869.4712469\n",
      "number of correct hits 1271\n",
      "labels tensor([ 0,  0,  2,  0,  0,  1,  0,  2,  0,  0])\n",
      "loss 0.966329693794\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1879.13454384\n",
      "number of correct hits 1278\n",
      "labels tensor([ 0,  2,  2,  0,  0,  0,  2,  0,  0,  2])\n",
      "loss 0.753359913826\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1886.66814297\n",
      "number of correct hits 1284\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  4,  0,  0,  0])\n",
      "loss 1.00744855404\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1896.74262851\n",
      "number of correct hits 1293\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  0,  0,  0,  0])\n",
      "loss 0.537578523159\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  2,  0])\n",
      "data size 10\n",
      "running loss 1902.11841375\n",
      "number of correct hits 1301\n",
      "labels tensor([ 0,  0,  1,  2,  1,  0,  0,  0,  0,  1])\n",
      "loss 1.33746767044\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1915.49309045\n",
      "number of correct hits 1307\n",
      "labels tensor([ 0,  1,  0,  2,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.847567260265\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1923.96876305\n",
      "number of correct hits 1314\n",
      "labels tensor([ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.610465705395\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1930.07342011\n",
      "number of correct hits 1323\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0])\n",
      "loss 0.546716332436\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1935.54058343\n",
      "number of correct hits 1332\n",
      "labels tensor([ 1,  0,  2,  0,  0,  0,  2,  0,  2,  0])\n",
      "loss 1.16834783554\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1947.22406179\n",
      "number of correct hits 1338\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  0,  2,  2,  0])\n",
      "loss 0.843685150146\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1955.66091329\n",
      "number of correct hits 1345\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  2,  0,  0,  0])\n",
      "loss 0.479355752468\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1960.45447081\n",
      "number of correct hits 1354\n",
      "labels tensor([ 0,  0,  3,  0,  0,  0,  0,  2,  3,  0])\n",
      "loss 1.29259943962\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1973.38046521\n",
      "number of correct hits 1361\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  2,  0,  0,  0])\n",
      "loss 0.520622253418\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1978.58668774\n",
      "number of correct hits 1370\n",
      "labels tensor([ 0,  0,  2,  2,  0,  2,  0,  0,  3,  2])\n",
      "loss 1.6731351614\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1995.31803936\n",
      "number of correct hits 1375\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  2,  0,  0,  0])\n",
      "loss 0.429947763681\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 1999.61751699\n",
      "number of correct hits 1384\n",
      "labels tensor([ 2,  0,  1,  0,  0,  0,  2,  0,  0,  0])\n",
      "loss 0.921485126019\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2008.83236825\n",
      "number of correct hits 1391\n",
      "labels tensor([ 2,  0,  2,  2,  0,  2,  0,  0,  0,  0])\n",
      "loss 1.00911152363\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2018.92348349\n",
      "number of correct hits 1397\n",
      "labels tensor([ 2,  0,  3,  0,  0,  0,  2,  0,  0,  0])\n",
      "loss 0.884821116924\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2027.77169466\n",
      "number of correct hits 1404\n",
      "labels tensor([ 2,  1,  0,  0,  0,  2,  0,  0,  2,  0])\n",
      "loss 1.07767891884\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2038.54848385\n",
      "number of correct hits 1410\n",
      "labels tensor([ 0,  0,  0,  0,  3,  0,  0,  0,  0,  0])\n",
      "loss 0.652695000172\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2045.07543385\n",
      "number of correct hits 1419\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0])\n",
      "loss 0.714772760868\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2052.22316146\n",
      "number of correct hits 1428\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  4,  1,  0,  0])\n",
      "loss 1.27134919167\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 10\n",
      "running loss 2064.93665338\n",
      "number of correct hits 1436\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.51802021265\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2070.1168555\n",
      "number of correct hits 1444\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.481470108032\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2074.93155658\n",
      "number of correct hits 1453\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  1,  0,  0,  0])\n",
      "loss 0.690883994102\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2081.84039652\n",
      "number of correct hits 1461\n",
      "labels tensor([ 0,  0,  2,  1,  1,  2,  4,  1,  0,  0])\n",
      "loss 2.49252390862\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2106.76563561\n",
      "number of correct hits 1465\n",
      "labels tensor([ 0,  0,  1,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.510551571846\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2111.87115133\n",
      "number of correct hits 1474\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.212810724974\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2113.99925858\n",
      "number of correct hits 1484\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.500140726566\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2119.00066584\n",
      "number of correct hits 1493\n",
      "labels tensor([ 4,  2,  2,  2,  0,  0,  0,  0,  0,  1])\n",
      "loss 1.49903535843\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2133.99101943\n",
      "number of correct hits 1498\n",
      "labels tensor([ 1,  0,  0,  3,  0,  2,  0,  1,  0,  0])\n",
      "loss 1.53276848793\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2149.31870431\n",
      "number of correct hits 1504\n",
      "labels tensor([ 0,  2,  1,  0,  0,  2,  0,  0,  2,  1])\n",
      "loss 1.30834722519\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2162.40217656\n",
      "number of correct hits 1509\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  3,  2,  0,  1])\n",
      "loss 1.15506839752\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2173.95286053\n",
      "number of correct hits 1515\n",
      "labels tensor([ 0,  0,  0,  0,  2,  0,  2,  2,  0,  0])\n",
      "loss 0.96274292469\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2183.58028978\n",
      "number of correct hits 1522\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  0,  1,  0,  0])\n",
      "loss 1.06057775021\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2194.18606728\n",
      "number of correct hits 1530\n",
      "labels tensor([ 0,  0,  0,  2,  0,  4,  0,  0,  1,  0])\n",
      "loss 1.23293912411\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2206.51545852\n",
      "number of correct hits 1537\n",
      "labels tensor([ 0,  2,  1,  1,  2,  2,  0,  0,  0,  0])\n",
      "loss 1.17799699306\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2218.29542845\n",
      "number of correct hits 1542\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  0,  0,  0,  4])\n",
      "loss 0.860265851021\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2226.89808697\n",
      "number of correct hits 1550\n",
      "labels tensor([ 2,  0,  1,  2,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.802082717419\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2234.91891414\n",
      "number of correct hits 1557\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  0,  0,  0,  4])\n",
      "loss 0.766609549522\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2242.58500963\n",
      "number of correct hits 1565\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3])\n",
      "loss 0.693120002747\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2249.51620966\n",
      "number of correct hits 1574\n",
      "labels tensor([ 0,  2,  0,  0,  0,  1,  0,  0,  0,  2])\n",
      "loss 1.07735705376\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2260.2897802\n",
      "number of correct hits 1581\n",
      "labels tensor([ 2,  0,  1,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.693312048912\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2267.22290069\n",
      "number of correct hits 1589\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0])\n",
      "loss 0.460438877344\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2271.82728946\n",
      "number of correct hits 1598\n",
      "labels tensor([ 0,  0,  0,  0,  2,  0,  0,  0,  0,  0])\n",
      "loss 0.401133388281\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2275.83862334\n",
      "number of correct hits 1607\n",
      "labels tensor([ 0,  3,  0,  0,  0,  0,  0,  0,  2,  2])\n",
      "loss 1.12507820129\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2287.08940536\n",
      "number of correct hits 1614\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  2,  0,  0,  0])\n",
      "loss 0.697952866554\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2294.06893402\n",
      "number of correct hits 1622\n",
      "labels tensor([ 0,  4,  0,  0,  0,  0,  0,  0,  0,  4])\n",
      "loss 1.22345376015\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2306.30347162\n",
      "number of correct hits 1630\n",
      "labels tensor([ 2,  0,  0,  0,  0,  1,  0,  0,  0,  2])\n",
      "loss 0.860542297363\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2314.9088946\n",
      "number of correct hits 1637\n",
      "labels tensor([ 0,  1,  0,  0,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.570099711418\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2320.60989171\n",
      "number of correct hits 1645\n",
      "labels tensor([ 0,  0,  0,  1,  2,  0,  0,  0,  0,  0])\n",
      "loss 0.851032733917\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2329.12021905\n",
      "number of correct hits 1653\n",
      "labels tensor([ 2,  2,  2,  0,  0,  2,  0,  0,  0,  0])\n",
      "loss 0.979788959026\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2338.91810864\n",
      "number of correct hits 1659\n",
      "labels tensor([ 0,  0,  0,  0,  0,  1,  1,  0,  2,  0])\n",
      "loss 0.86888217926\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2347.60693043\n",
      "number of correct hits 1666\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  1,  0,  0,  0])\n",
      "loss 0.87546557188\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2356.36158615\n",
      "number of correct hits 1674\n",
      "labels tensor([ 2,  0,  2,  0,  2,  0,  0,  3,  2,  0])\n",
      "loss 1.12270724773\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2367.58865863\n",
      "number of correct hits 1679\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0])\n",
      "loss 0.615236222744\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2373.74102086\n",
      "number of correct hits 1688\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  3,  0,  0,  0])\n",
      "loss 0.742965102196\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  2,  0])\n",
      "data size 10\n",
      "running loss 2381.17067188\n",
      "number of correct hits 1696\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.553335487843\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2386.70402676\n",
      "number of correct hits 1705\n",
      "labels tensor([ 0,  1,  0,  0,  0,  1,  0,  0,  0,  0])\n",
      "loss 0.840849280357\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2395.11251956\n",
      "number of correct hits 1713\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.451677411795\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2399.62929368\n",
      "number of correct hits 1722\n",
      "labels tensor([ 0,  1,  0,  0,  2,  0,  0,  0,  3,  0])\n",
      "loss 1.11110568047\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2410.74035048\n",
      "number of correct hits 1729\n",
      "labels tensor([ 0,  1,  0,  0,  4,  0,  0,  0,  0,  0])\n",
      "loss 0.99899405241\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2420.73029101\n",
      "number of correct hits 1737\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  0,  0,  0,  0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.33855432272\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2424.11583424\n",
      "number of correct hits 1746\n",
      "labels tensor([ 0,  0,  0,  0,  0,  3,  0,  0,  0,  0])\n",
      "loss 0.444992870092\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2428.56576294\n",
      "number of correct hits 1755\n",
      "labels tensor([ 0,  1,  0,  2,  0,  0,  2,  1,  0,  2])\n",
      "loss 1.85588991642\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2447.1246621\n",
      "number of correct hits 1760\n",
      "labels tensor([ 0,  0,  2,  0,  2,  0,  0,  0,  0,  0])\n",
      "loss 0.645306944847\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2453.57773155\n",
      "number of correct hits 1768\n",
      "labels tensor([ 0,  0,  1,  0,  0,  1,  0,  0,  0,  0])\n",
      "loss 0.738888859749\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2460.96662015\n",
      "number of correct hits 1776\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.142015978694\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2462.38677993\n",
      "number of correct hits 1786\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  2,  4,  0,  2])\n",
      "loss 1.30745232105\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2475.46130314\n",
      "number of correct hits 1792\n",
      "labels tensor([ 0,  0,  2,  2,  0,  0,  3,  0,  0,  0])\n",
      "loss 1.0750451088\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2486.21175423\n",
      "number of correct hits 1799\n",
      "labels tensor([ 2,  0,  0,  1,  4,  0,  2,  0,  0,  2])\n",
      "loss 1.64289355278\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2502.64068976\n",
      "number of correct hits 1804\n",
      "labels tensor([ 0,  0,  1,  1,  2,  0,  2,  0,  0,  0])\n",
      "loss 1.17559528351\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2514.3966426\n",
      "number of correct hits 1810\n",
      "labels tensor([ 2,  0,  0,  0,  0,  2,  0,  0,  0,  1])\n",
      "loss 0.926968693733\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2523.66632953\n",
      "number of correct hits 1817\n",
      "labels tensor([ 0,  0,  2,  0,  0,  1,  0,  0,  2,  0])\n",
      "loss 0.978953182697\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2533.45586136\n",
      "number of correct hits 1824\n",
      "labels tensor([ 2,  2,  0,  0,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.711265981197\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2540.56852117\n",
      "number of correct hits 1831\n",
      "labels tensor([ 0,  0,  1,  4,  2,  0,  0,  3,  2,  0])\n",
      "loss 1.59905076027\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2556.55902877\n",
      "number of correct hits 1836\n",
      "labels tensor([ 0,  4,  4,  0,  3,  2,  0,  1,  0,  2])\n",
      "loss 1.93017923832\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2575.86082116\n",
      "number of correct hits 1840\n",
      "labels tensor([ 0,  0,  0,  0,  0,  4,  0,  2,  2,  0])\n",
      "loss 1.14805006981\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2587.34132186\n",
      "number of correct hits 1847\n",
      "labels tensor([ 0,  0,  2,  0,  2,  1,  0,  0,  2,  0])\n",
      "loss 1.05460143089\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2597.88733616\n",
      "number of correct hits 1853\n",
      "labels tensor([ 0,  0,  1,  2,  0,  0,  2,  2,  0,  0])\n",
      "loss 1.03741335869\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2608.26146975\n",
      "number of correct hits 1859\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2])\n",
      "loss 0.701388478279\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2615.27535453\n",
      "number of correct hits 1868\n",
      "labels tensor([ 0,  0,  0,  0,  1,  0,  2,  1,  0,  0])\n",
      "loss 1.15470159054\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2626.82237044\n",
      "number of correct hits 1875\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  0,  0,  2,  0])\n",
      "loss 0.671044588089\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2633.53281632\n",
      "number of correct hits 1883\n",
      "labels tensor([ 0,  2,  2,  0,  1,  2,  0,  0,  2,  3])\n",
      "loss 1.60451221466\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2649.57793847\n",
      "number of correct hits 1887\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  0,  2])\n",
      "loss 0.65453517437\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2656.12329021\n",
      "number of correct hits 1895\n",
      "labels tensor([ 0,  0,  3,  0,  2,  2,  0,  0,  2,  0])\n",
      "loss 1.12244033813\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2667.34769359\n",
      "number of correct hits 1901\n",
      "labels tensor([ 2,  2,  0,  0,  0,  2,  0,  4,  0,  0])\n",
      "loss 1.03184962273\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2677.66618982\n",
      "number of correct hits 1907\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  0,  0,  0,  0])\n",
      "loss 0.479701906443\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2682.46320888\n",
      "number of correct hits 1916\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  0,  0,  0,  2])\n",
      "loss 0.520972847939\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2687.67293736\n",
      "number of correct hits 1924\n",
      "labels tensor([ 0,  0,  0,  2,  0,  1,  0,  4,  0,  0])\n",
      "loss 1.39238357544\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2701.59677312\n",
      "number of correct hits 1931\n",
      "labels tensor([ 1,  0,  0,  0,  0,  0,  4,  0,  2,  0])\n",
      "loss 1.01830625534\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2711.77983567\n",
      "number of correct hits 1938\n",
      "labels tensor([ 2,  0,  1,  1,  0,  0,  0,  2,  0,  1])\n",
      "loss 1.58106207848\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2727.59045646\n",
      "number of correct hits 1943\n",
      "labels tensor([ 1,  0,  0,  0,  0,  0,  1,  0,  2,  0])\n",
      "loss 1.29211330414\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2740.5115895\n",
      "number of correct hits 1950\n",
      "labels tensor([ 2,  0,  2,  0,  2,  2,  2,  0,  0,  2])\n",
      "loss 1.29892277718\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2753.50081727\n",
      "number of correct hits 1954\n",
      "labels tensor([ 0,  0,  0,  0,  3,  0,  2,  0,  0,  0])\n",
      "loss 1.33639955521\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2766.86481282\n",
      "number of correct hits 1962\n",
      "labels tensor([ 0,  0,  2,  0,  0,  0,  0,  2,  0,  0])\n",
      "loss 0.730274379253\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2774.16755661\n",
      "number of correct hits 1970\n",
      "labels tensor([ 2,  0,  2,  2,  0,  2,  0,  2,  1,  0])\n",
      "loss 1.23261702061\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2786.49372682\n",
      "number of correct hits 1974\n",
      "labels tensor([ 0,  0,  1,  0,  3,  0,  4,  1,  0,  0])\n",
      "loss 1.62603759766\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2802.7541028\n",
      "number of correct hits 1980\n",
      "labels tensor([ 2,  0,  1,  1,  0,  0,  0,  0,  0,  1])\n",
      "loss 1.14631211758\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2814.21722397\n",
      "number of correct hits 1986\n",
      "labels tensor([ 0,  0,  0,  2,  0,  1,  2,  0,  0,  0])\n",
      "loss 0.887627005577\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2823.09349403\n",
      "number of correct hits 1993\n",
      "labels tensor([ 2,  0,  0,  1,  0,  1,  0,  0,  2,  1])\n",
      "loss 1.20198011398\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2835.11329517\n",
      "number of correct hits 1998\n",
      "labels tensor([ 0,  0,  1,  0,  0,  2,  2,  0,  0,  0])\n",
      "loss 1.04938805103\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2845.60717568\n",
      "number of correct hits 2005\n",
      "labels tensor([ 2,  3,  0,  1,  0,  0,  0,  0,  2,  2])\n",
      "loss 1.3175894022\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 10\n",
      "running loss 2858.7830697\n",
      "number of correct hits 2010\n",
      "labels tensor([ 0,  0,  0,  0,  0,  2,  1,  2,  3,  0])\n",
      "loss 1.29037845135\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2871.68685421\n",
      "number of correct hits 2016\n",
      "labels tensor([ 0,  0,  0,  2,  2,  0,  0,  0,  0,  0])\n",
      "loss 0.837587535381\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2880.06272957\n",
      "number of correct hits 2024\n",
      "labels tensor([ 0,  0,  0,  0,  2,  0,  0,  0,  0,  0])\n",
      "loss 0.668532371521\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2886.74805328\n",
      "number of correct hits 2033\n",
      "labels tensor([ 0,  0,  0,  2,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.552187979221\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2892.26993307\n",
      "number of correct hits 2042\n",
      "labels tensor([ 0,  3,  1,  0,  0,  0,  2,  2,  2,  0])\n",
      "loss 1.57606577873\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2908.03059086\n",
      "number of correct hits 2047\n",
      "labels tensor([ 0,  0,  0,  0,  0,  1,  1,  0,  2,  0])\n",
      "loss 0.992807090282\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2917.95866176\n",
      "number of correct hits 2054\n",
      "labels tensor([ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.502848744392\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2922.98714921\n",
      "number of correct hits 2063\n",
      "labels tensor([ 0,  0,  0,  0,  1,  1,  2,  0,  0,  1])\n",
      "loss 1.35350847244\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2936.52223393\n",
      "number of correct hits 2069\n",
      "labels tensor([ 0,  0,  3,  0,  2,  0,  0,  0,  0,  0])\n",
      "loss 0.957628130913\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2946.09851524\n",
      "number of correct hits 2077\n",
      "labels tensor([ 0,  4,  0,  0,  0,  2,  1,  2,  3,  0])\n",
      "loss 1.76110816002\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2963.70959684\n",
      "number of correct hits 2082\n",
      "labels tensor([ 2,  0,  0,  0,  0,  0,  0,  0,  0,  1])\n",
      "loss 0.790800392628\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2971.61760077\n",
      "number of correct hits 2090\n",
      "labels tensor([ 0,  0,  2,  2,  0,  0,  0,  0,  0,  0])\n",
      "loss 0.577363908291\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2977.39123985\n",
      "number of correct hits 2098\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0])\n",
      "loss 0.514691650867\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2982.53815636\n",
      "number of correct hits 2107\n",
      "labels tensor([ 0,  0,  3,  0,  0,  0,  2,  0,  3,  0])\n",
      "loss 1.48516142368\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 2997.3897706\n",
      "number of correct hits 2114\n",
      "labels tensor([ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0])\n",
      "loss 0.595422744751\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 3003.34399804\n",
      "number of correct hits 2123\n",
      "labels tensor([ 0,  0,  2,  2,  0,  0,  2,  0,  0,  1])\n",
      "loss 1.13553881645\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "data size 10\n",
      "running loss 3014.69938621\n",
      "number of correct hits 2129\n",
      "labels tensor([ 0,  2,  0,  0,  0,  0,  0,  0,  0,  4])\n",
      "loss 0.813318610191\n",
      "predictions tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "Process Process-11:\n",
      "Process Process-12:\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "    return recv()\n",
      "    return recv()\n",
      "    return recv()\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    return recv()\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "  File \"/home/eslam/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "    buf = self.recv_bytes()\n",
      "    buf = self.recv_bytes()\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8c442b5c3170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#### plotting ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#x = np.arange(num_epochs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-edf220fb3a31>\u001b[0m in \u001b[0;36mtrain_model_cpu\u001b[0;34m(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eslam/anaconda2/lib/python2.7/site-packages/torch/optim/adam.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#use_cuda = torch.cuda.is_available()\n",
    "model = ConvNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "criterion = nn.NLLLoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "accuracy =0\n",
    "num_epochs = 25\n",
    "mymodel, accuracy=train_model_cpu(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, num_epochs=num_epochs)\n",
    "#### plotting ####\n",
    "#x = np.arange(num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "model = ConvNet().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "#criterion = nn.NLLLoss().cuda()\n",
    "criterion = nn.NLLLoss().cuda()\n",
    "accuracy =0\n",
    "num_epochs = 25\n",
    "true = []\n",
    "pred = []\n",
    "class_names = ['0', '1', '2', '3', '4']\n",
    "mymodel, train_losses, train_acc, val_losses, val_acc=train_model(model, dataloader_train, dataloader_val, criterion, optimizer, scheduler, num_epochs=25)\n",
    "accuracy = test_model(mymodel, dataloader_test, criterion, optimizer, scheduler, num_epochs = 25)\n",
    "plot_conf_matrix(true, pred, class_names)\n",
    "\n",
    "### plotting ###\n",
    "epochsRange = np.array(range(num_epochs))\n",
    "plt.plot(epochsRange, train_losses, label='Training')\n",
    "plt.plot(epochsRange, val_losses, label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochsRange, train_acc, label='Training')\n",
    "plt.plot(epochsRange, val_acc, label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
